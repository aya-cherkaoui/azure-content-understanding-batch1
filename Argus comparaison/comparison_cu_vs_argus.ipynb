{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020401df",
   "metadata": {},
   "source": [
    "# Comparaison : Content Understanding vs ARGUS\n",
    "\n",
    "Comparaison de deux approches d'extraction documentaire appliquÃ©es au mÃªme batch de **20 factures** (batch1).\n",
    "\n",
    "## MÃ©thodes comparÃ©es\n",
    "| | MÃ©thode 1 â€“ Content Understanding | MÃ©thode 2 â€“ ARGUS |\n",
    "|---|---|---|\n",
    "| **Repo** | Notre pipeline (`docu_prebuilt_invoice.ipynb`) | [Azure-Samples/ARGUS](https://github.com/Azure-Samples/ARGUS) |\n",
    "| **Approche** | API prÃ©-entraÃ®nÃ©e `prebuilt-invoice` | OCR + GPT-4 Vision (hybrid pipeline) |\n",
    "| **Philosophie** | Extraction directe, schÃ©ma fixe | Extraction flexible, schÃ©ma personnalisable |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244636f2",
   "metadata": {},
   "source": [
    "## 1. Comparaison des Architectures\n",
    "\n",
    "| CritÃ¨re | Content Understanding (MÃ©thode 1) | ARGUS (MÃ©thode 2) |\n",
    "|---|---|---|\n",
    "| **OCR / Extraction** | ModÃ¨le prÃ©-entraÃ®nÃ© `prebuilt-invoice` (Content Understanding API v2025-11-01) | Azure Document Intelligence `prebuilt-layout` â†’ texte markdown |\n",
    "| **Structuration** | 31 champs invoice extraits automatiquement par le modÃ¨le | GPT-4 Vision reÃ§oit OCR text + images â†’ JSON libre selon schema |\n",
    "| **SchÃ©ma** | Fixe (31 champs Microsoft prÃ©dÃ©finis) | Configurable par dataset (prompt + schema personnalisÃ©) |\n",
    "| **RÃ´le du LLM** | GPT-4.1 Vision pour description textuelle uniquement (optionnel) | GPT-4 Vision pour extraction structurÃ©e + Ã©valuation + rÃ©sumÃ© |\n",
    "| **Pipeline** | Upload Blob â†’ SAS URL â†’ Content Understanding â†’ (LLM description) | Upload Blob â†’ Event Grid â†’ OCR â†’ GPT Extraction â†’ GPT Evaluation â†’ GPT Summary |\n",
    "| **Stockage rÃ©sultats** | Fichiers JSON locaux | Azure Cosmos DB + Blob Storage |\n",
    "| **Infrastructure** | Notebook Python + API REST | FastAPI + Container Apps + Logic Apps + Cosmos DB |\n",
    "| **Ã‰valuation qualitÃ©** | Confidence scores natifs du modÃ¨le (par champ) | GPT Ã©value chaque champ extrait avec confidence scores + accuracy |\n",
    "| **CoÃ»t estimÃ©/doc** | ~$0.01-0.02 (CU) + ~$0.03 (LLM opt.) | ~$0.01 (DI) + ~$0.10-0.30 (3Ã— GPT-4 Vision) |\n",
    "| **FlexibilitÃ© schÃ©ma** | âŒ Fixe | âœ… Totalement configurable |\n",
    "| **Auto-Ã©valuation** | âŒ | âœ… Confidence scores + accuracy % |\n",
    "| **Chat avec documents** | âŒ | âœ… Endpoint `/api/chat` intÃ©grÃ© |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a928e",
   "metadata": {},
   "source": [
    "## 2. Pipeline DÃ©taillÃ©\n",
    "\n",
    "### Content Understanding (notre approche)\n",
    "```\n",
    "Image JPG\n",
    "  â†’ Upload Azure Blob Storage (SAS URL)\n",
    "  â†’ Content Understanding API (prebuilt-invoice, v2025-11-01)\n",
    "      â†’ markdown structurÃ© + 31 champs typÃ©s (automatique, 1 appel)\n",
    "  â†’ GPT-4.1 Vision (optionnel)\n",
    "      â†’ description textuelle du document\n",
    "  â†’ Sauvegarde JSON local\n",
    "```\n",
    "\n",
    "### ARGUS (Azure-Samples/ARGUS)\n",
    "```\n",
    "PDF/Image\n",
    "  â†’ Upload Azure Blob Storage\n",
    "  â†’ Event Grid trigger â†’ FastAPI Backend (Container Apps)\n",
    "  â†’ Ã‰tape 1: Azure Document Intelligence (prebuilt-layout)\n",
    "      â†’ OCR markdown (texte brut structurÃ©)\n",
    "  â†’ Ã‰tape 2: PyMuPDF â†’ conversion PDF en images PNG (base64)\n",
    "  â†’ Ã‰tape 3: GPT-4 Vision (OCR text + images + system prompt + output schema)\n",
    "      â†’ JSON structurÃ© selon le schÃ©ma personnalisÃ©\n",
    "  â†’ Ã‰tape 4: GPT-4 Vision (Ã©valuation)\n",
    "      â†’ confidence scores (0-1) par champ + accuracy globale\n",
    "  â†’ Ã‰tape 5: GPT (rÃ©sumÃ©)\n",
    "      â†’ rÃ©sumÃ© textuel du document\n",
    "  â†’ Stockage Cosmos DB (document complet + metadata)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867ea021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BibliothÃ¨ques chargÃ©es\n",
      "   DOC_INTELLIGENCE_ENDPOINT: https://docintel-argus-test.cognitiveservices.azur...\n",
      "   GPT_ENDPOINT: https://content-understanding--resource.cognitiveservices.az...\n"
     ]
    }
   ],
   "source": [
    "# === Section 1: Import des bibliothÃ¨ques ===\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import statistics\n",
    "import time\n",
    "import base64\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… BibliothÃ¨ques chargÃ©es\")\n",
    "print(f\"   DOC_INTELLIGENCE_ENDPOINT: {os.getenv('DOC_INTELLIGENCE_ENDPOINT', 'âŒ manquant')[:50]}...\")\n",
    "print(f\"   GPT_ENDPOINT: {os.getenv('GPT_ENDPOINT', 'âŒ manquant')[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1438ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Content Understanding: 20 documents chargÃ©s\n",
      "\n",
      "Document               Champs   Markdown   Conf.moy   LLM\n",
      "----------------------------------------------------------\n",
      "batch1-0001.json      17/31        2,011     0.820     âœ…\n",
      "batch1-0002.json      17/31        1,663     0.830     âŒ\n",
      "batch1-0003.json      17/31        1,339     0.825     âŒ\n",
      "batch1-0004.json      17/31        1,697     0.819     âŒ\n",
      "batch1-0005.json      17/31        1,636     0.809     âŒ\n",
      "batch1-0006.json       0/31        1,507     0.720     âŒ\n",
      "batch1-0007.json      17/31        2,060     0.815     âœ…\n",
      "batch1-0008.json      17/31        1,521     0.825     âœ…\n",
      "batch1-0009.json      17/31        1,029     0.822     âŒ\n",
      "batch1-0010.json      17/31        1,093     0.816     âŒ\n",
      "batch1-0011.json      17/31        1,076     0.815     âŒ\n",
      "batch1-0012.json      17/31        1,390     0.814     âœ…\n",
      "batch1-0013.json      17/31        1,529     0.813     âœ…\n",
      "batch1-0014.json      17/31          887     0.811     âœ…\n",
      "batch1-0015.json      17/31        1,780     0.829     âœ…\n",
      "batch1-0016.json      17/31        1,638     0.812     âœ…\n",
      "batch1-0017.json      17/31        1,613     0.823     âœ…\n",
      "batch1-0018.json      17/31        1,732     0.823     âœ…\n",
      "batch1-0019.json      17/31        1,236     0.814     âœ…\n",
      "batch1-0020.json      17/31        1,680     0.817     âœ…\n"
     ]
    }
   ],
   "source": [
    "# === Section 2: Charger les rÃ©sultats Content Understanding ===\n",
    "CU_RESULTS_DIR = r\"c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\docu_results_batch1_1\\prebuilt-invoice\"\n",
    "cu_files = sorted(glob.glob(os.path.join(CU_RESULTS_DIR, \"batch1-*.json\")))\n",
    "\n",
    "cu_metrics = []\n",
    "for f in cu_files:\n",
    "    with open(f, encoding=\"utf-8\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    fname = os.path.basename(f)\n",
    "    contents = data.get(\"result\", {}).get(\"contents\", [{}])\n",
    "    fields = contents[0].get(\"fields\", {}) if contents else {}\n",
    "    markdown = contents[0].get(\"markdown\", \"\") if contents else \"\"\n",
    "\n",
    "    # Compter les champs avec valeur rÃ©elle\n",
    "    fields_with_value = 0\n",
    "    field_names_with_value = []\n",
    "    for k, v in fields.items():\n",
    "        has_val = False\n",
    "        ftype = v.get(\"type\", \"\")\n",
    "        if ftype == \"object\":\n",
    "            vo = v.get(\"valueObject\", {})\n",
    "            for sk, sv in vo.items():\n",
    "                if isinstance(sv, dict):\n",
    "                    for vkey in [\"valueString\", \"valueNumber\", \"valueDate\"]:\n",
    "                        if sv.get(vkey) is not None:\n",
    "                            has_val = True\n",
    "                            break\n",
    "        elif ftype == \"array\":\n",
    "            arr = v.get(\"valueArray\", [])\n",
    "            if arr and len(arr) > 0:\n",
    "                has_val = True\n",
    "        else:\n",
    "            for vkey in [\"valueString\", \"valueNumber\", \"valueDate\"]:\n",
    "                if v.get(vkey) is not None:\n",
    "                    has_val = True\n",
    "                    break\n",
    "        if has_val:\n",
    "            fields_with_value += 1\n",
    "            field_names_with_value.append(k)\n",
    "\n",
    "    # Confidence scores\n",
    "    confidences = []\n",
    "    for k, v in fields.items():\n",
    "        c = v.get(\"confidence\")\n",
    "        if c is not None:\n",
    "            confidences.append(c)\n",
    "        vo = v.get(\"valueObject\", {})\n",
    "        for sk, sv in vo.items():\n",
    "            if isinstance(sv, dict) and sv.get(\"confidence\") is not None:\n",
    "                confidences.append(sv[\"confidence\"])\n",
    "\n",
    "    # LLM description\n",
    "    extracted = data.get(\"_extracted\", {})\n",
    "    desc = extracted.get(\"description\", \"\")\n",
    "    llm_ok = bool(desc) and \"error\" not in str(desc).lower()[:80]\n",
    "\n",
    "    cu_metrics.append({\n",
    "        \"file\": fname,\n",
    "        \"fields_with_value\": fields_with_value,\n",
    "        \"total_fields\": len(fields),\n",
    "        \"field_names\": field_names_with_value,\n",
    "        \"markdown_chars\": len(markdown),\n",
    "        \"avg_confidence\": statistics.mean(confidences) if confidences else 0,\n",
    "        \"min_confidence\": min(confidences) if confidences else 0,\n",
    "        \"llm_description\": \"âœ…\" if llm_ok else \"âŒ\",\n",
    "    })\n",
    "\n",
    "print(f\"ğŸ“„ Content Understanding: {len(cu_metrics)} documents chargÃ©s\\n\")\n",
    "print(f\"{'Document':<20} {'Champs':>8} {'Markdown':>10} {'Conf.moy':>10} {'LLM':>5}\")\n",
    "print(\"-\" * 58)\n",
    "for m in cu_metrics:\n",
    "    print(f\"{m['file']:<20} {m['fields_with_value']:>3}/{m['total_fields']:<4} {m['markdown_chars']:>10,} {m['avg_confidence']:>9.3f} {m['llm_description']:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61442a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "   MÃ‰TRIQUES AGRÃ‰GÃ‰ES â€” CONTENT UNDERSTANDING\n",
      "============================================================\n",
      "  Documents traitÃ©s      : 20\n",
      "  Champs/doc (moyenne)   : 16.1 / 31\n",
      "  Champs/doc (min/max)   : 0 / 17\n",
      "  Docs sans champs (=0)  : 1\n",
      "  Markdown chars (moy)   : 1,506\n",
      "  Confidence moyenne     : 0.814\n",
      "  Confidence min         : 0.720\n",
      "  LLM description OK     : 12/20\n",
      "  Taux extraction        : 19/20 (95%)\n",
      "\n",
      "  Top 10 champs extraits:\n",
      "    AmountDue                      â†’ 19/20 docs\n",
      "    CountryRegion                  â†’ 19/20 docs\n",
      "    CustomerAddress                â†’ 19/20 docs\n",
      "    CustomerAddressRecipient       â†’ 19/20 docs\n",
      "    CustomerName                   â†’ 19/20 docs\n",
      "    CustomerTaxId                  â†’ 19/20 docs\n",
      "    InvoiceDate                    â†’ 19/20 docs\n",
      "    InvoiceId                      â†’ 19/20 docs\n",
      "    LineItems                      â†’ 19/20 docs\n",
      "    SubtotalAmount                 â†’ 19/20 docs\n"
     ]
    }
   ],
   "source": [
    "# === Section 3: MÃ©triques agrÃ©gÃ©es Content Understanding ===\n",
    "cu_fields = [m[\"fields_with_value\"] for m in cu_metrics]\n",
    "cu_markdown = [m[\"markdown_chars\"] for m in cu_metrics]\n",
    "cu_confs = [m[\"avg_confidence\"] for m in cu_metrics if m[\"avg_confidence\"] > 0]\n",
    "cu_llm_ok = sum(1 for m in cu_metrics if m[\"llm_description\"] == \"âœ…\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"   MÃ‰TRIQUES AGRÃ‰GÃ‰ES â€” CONTENT UNDERSTANDING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Documents traitÃ©s      : {len(cu_metrics)}\")\n",
    "print(f\"  Champs/doc (moyenne)   : {statistics.mean(cu_fields):.1f} / {cu_metrics[0]['total_fields']}\")\n",
    "print(f\"  Champs/doc (min/max)   : {min(cu_fields)} / {max(cu_fields)}\")\n",
    "print(f\"  Docs sans champs (=0)  : {sum(1 for f in cu_fields if f == 0)}\")\n",
    "print(f\"  Markdown chars (moy)   : {statistics.mean(cu_markdown):,.0f}\")\n",
    "print(f\"  Confidence moyenne     : {statistics.mean(cu_confs):.3f}\" if cu_confs else \"  Confidence moyenne     : N/A\")\n",
    "print(f\"  Confidence min         : {min(cu_confs):.3f}\" if cu_confs else \"  Confidence min         : N/A\")\n",
    "print(f\"  LLM description OK     : {cu_llm_ok}/{len(cu_metrics)}\")\n",
    "print(f\"  Taux extraction        : {sum(1 for f in cu_fields if f > 0)}/{len(cu_metrics)} ({sum(1 for f in cu_fields if f > 0)/len(cu_metrics)*100:.0f}%)\")\n",
    "\n",
    "# Champs les plus extraits\n",
    "all_field_names = []\n",
    "for m in cu_metrics:\n",
    "    all_field_names.extend(m[\"field_names\"])\n",
    "field_counts = Counter(all_field_names)\n",
    "print(f\"\\n  Top 10 champs extraits:\")\n",
    "for name, count in field_counts.most_common(10):\n",
    "    print(f\"    {name:<30} â†’ {count}/{len(cu_metrics)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029516a3",
   "metadata": {},
   "source": [
    "## 3. Pipeline ARGUS-style (exÃ©cution rÃ©elle)\n",
    "\n",
    "On **exÃ©cute** le pipeline ARGUS sur nos mÃªmes 20 factures en rÃ©pliquant ses Ã©tapes clÃ©s :\n",
    "1. **OCR Option A** : Azure Document Intelligence `prebuilt-layout` (texte markdown)\n",
    "2. **OCR Option B** : Mistral Doc AI (OCR alternatif)\n",
    "3. **GPT-5-chat** pour l'extraction structurÃ©e (OCR text + images + prompt ARGUS + schema)\n",
    "\n",
    "> **Services utilisÃ©s** :\n",
    "> - Document Intelligence : `docintel-argus-test` (API key auth)\n",
    "> - Mistral Doc AI : `content-understanding--resource` (API key auth)\n",
    "> - GPT-5-chat : `content-understanding--resource` (API key auth)\n",
    "> - Credentials chargÃ©es depuis `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bearer token obtenu (2283 chars)\n",
      "\n",
      "âœ… Pipeline ARGUS-style prÃªt (3 services)\n",
      "   OCR A : Document Intelligence prebuilt-layout (API key)\n",
      "   OCR B : Mistral Doc AI (API key)\n",
      "   LLM   : GPT-5-chat (Bearer token / Entra ID)\n",
      "   Schema: 15 champs de premier niveau\n"
     ]
    }
   ],
   "source": [
    "# === Section 4: ImplÃ©mentation du pipeline ARGUS-style ===\n",
    "# Pipeline : OCR (Doc Intelligence OU Mistral Doc AI) â†’ GPT-5-chat extraction\n",
    "\n",
    "# --- Credentials from .env ---\n",
    "DI_ENDPOINT = os.environ[\"DOC_INTELLIGENCE_ENDPOINT\"].rstrip(\"/\")\n",
    "DI_KEY = os.environ[\"DOC_INTELLIGENCE_KEY\"]\n",
    "\n",
    "MISTRAL_ENDPOINT = os.environ[\"MISTRAL_DOC_AI_ENDPOINT\"]\n",
    "MISTRAL_KEY = os.environ[\"MISTRAL_DOC_AI_KEY\"]\n",
    "\n",
    "# GPT-5-chat : key auth dÃ©sactivÃ©e â†’ utiliser Bearer token (Entra ID)\n",
    "from azure.identity import DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "GPT_BASE_URL = \"https://content-understanding--resource.cognitiveservices.azure.com\"\n",
    "GPT_DEPLOYMENT = \"gpt-5-chat\"\n",
    "GPT_API_VERSION = \"2025-01-01-preview\"\n",
    "GPT_FULL_URL = f\"{GPT_BASE_URL}/openai/deployments/{GPT_DEPLOYMENT}/chat/completions?api-version={GPT_API_VERSION}\"\n",
    "\n",
    "def get_bearer_token():\n",
    "    \"\"\"Obtenir un Bearer token pour Azure AI Services (Entra ID auth).\"\"\"\n",
    "    return credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "\n",
    "# =====================================================================\n",
    "#  OCR Option A : Azure Document Intelligence (prebuilt-layout)\n",
    "# =====================================================================\n",
    "def get_di_ocr_markdown(image_path: str) -> str:\n",
    "    \"\"\"OCR via Azure Document Intelligence prebuilt-layout â†’ markdown\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_data = f.read()\n",
    "\n",
    "    mime = \"image/jpeg\" if image_path.lower().endswith((\".jpg\", \".jpeg\")) else \"image/png\"\n",
    "\n",
    "    resp = requests.post(\n",
    "        f\"{DI_ENDPOINT}/formrecognizer/documentModels/prebuilt-layout:analyze?api-version=2023-07-31&outputContentFormat=markdown\",\n",
    "        headers={\n",
    "            \"Ocp-Apim-Subscription-Key\": DI_KEY,\n",
    "            \"Content-Type\": mime,\n",
    "        },\n",
    "        data=image_data,\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    op_url = resp.headers[\"Operation-Location\"]\n",
    "\n",
    "    for _ in range(60):\n",
    "        time.sleep(2)\n",
    "        r = requests.get(op_url, headers={\"Ocp-Apim-Subscription-Key\": DI_KEY}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        result = r.json()\n",
    "        if result[\"status\"] == \"succeeded\":\n",
    "            return result.get(\"analyzeResult\", {}).get(\"content\", \"\")\n",
    "        elif result[\"status\"] == \"failed\":\n",
    "            return f\"ERROR: {result}\"\n",
    "    return \"ERROR: timeout\"\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "#  OCR Option B : Mistral Document AI (mistral-document-ai-2505 via Azure)\n",
    "#  - Auth: Bearer token (Entra ID) car key auth dÃ©sactivÃ©e sur cette ressource\n",
    "#  - API: /providers/mistral/azure/ocr\n",
    "#  - Format: type=\"document_url\", document_url=\"data:<mime>;base64,...\"\n",
    "# =====================================================================\n",
    "def get_mistral_ocr_markdown(image_path: str) -> str:\n",
    "    \"\"\"OCR via Mistral Document AI (Azure-hosted) â†’ markdown\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_data = f.read()\n",
    "\n",
    "    b64_image = base64.b64encode(image_data).decode()\n",
    "    mime = \"image/jpeg\" if image_path.lower().endswith((\".jpg\", \".jpeg\")) else \"image/png\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-document-ai-2505\",\n",
    "        \"document\": {\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\": f\"data:{mime};base64,{b64_image}\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    token = get_bearer_token()\n",
    "    resp = requests.post(\n",
    "        MISTRAL_ENDPOINT,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=payload,\n",
    "        timeout=120,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    result = resp.json()\n",
    "\n",
    "    pages = result.get(\"pages\", [])\n",
    "    markdown_parts = [p.get(\"markdown\", \"\") for p in pages]\n",
    "    return \"\\n\\n\".join(markdown_parts)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "#  GPT-5-chat extraction (Bearer token auth, pattern ARGUS)\n",
    "# =====================================================================\n",
    "ARGUS_SYSTEM_PROMPT = \"\"\"Extract all data from the document in a comprehensive and structured manner.\n",
    "\n",
    "Focus on:\n",
    "- Key identifiers (invoice numbers, reference numbers, IDs)\n",
    "- Financial information (amounts, totals, currency, taxes)\n",
    "- Parties involved (vendors, customers, suppliers, recipients)\n",
    "- Dates and timelines (invoice dates, due dates, service periods)\n",
    "- Line items and details (products, services, quantities, prices)\n",
    "- Contact information (addresses, phone numbers, emails)\n",
    "- Any other relevant structured data visible in the document\n",
    "\n",
    "When both text and images are available, use the text as the primary source and cross-reference with images for accuracy.\"\"\"\n",
    "\n",
    "ARGUS_SCHEMA = {\n",
    "    \"invoice_number\": \"string\",\n",
    "    \"invoice_date\": \"string\",\n",
    "    \"due_date\": \"string\",\n",
    "    \"seller_name\": \"string\",\n",
    "    \"seller_address\": \"string\",\n",
    "    \"seller_tax_id\": \"string\",\n",
    "    \"buyer_name\": \"string\",\n",
    "    \"buyer_address\": \"string\",\n",
    "    \"buyer_tax_id\": \"string\",\n",
    "    \"iban\": \"string\",\n",
    "    \"line_items\": [{\"description\": \"string\", \"quantity\": \"number\", \"unit_price\": \"number\", \"net_worth\": \"number\", \"vat_rate\": \"string\", \"gross_worth\": \"number\"}],\n",
    "    \"subtotal\": \"number\",\n",
    "    \"total_tax\": \"number\",\n",
    "    \"total_amount\": \"number\",\n",
    "    \"currency\": \"string\"\n",
    "}\n",
    "\n",
    "\n",
    "def gpt_extract_argus_style(ocr_text: str, image_path: str) -> dict:\n",
    "    \"\"\"GPT-5-chat extraction avec OCR text + image (Bearer token auth)\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode()\n",
    "\n",
    "    mime = \"image/jpeg\" if image_path.lower().endswith((\".jpg\", \".jpeg\")) else \"image/png\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"{ARGUS_SYSTEM_PROMPT}\n",
    "\n",
    "Output the extracted data as JSON matching this schema:\n",
    "{json.dumps(ARGUS_SCHEMA, indent=2)}\n",
    "\n",
    "Return ONLY valid JSON, no markdown formatting.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"Here is the OCR text extracted from the document:\\n\\n{ocr_text}\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime};base64,{b64}\"}}\n",
    "        ]}\n",
    "    ]\n",
    "\n",
    "    token = get_bearer_token()\n",
    "    resp = requests.post(\n",
    "        GPT_FULL_URL,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        json={\"messages\": messages, \"max_tokens\": 4096, \"temperature\": 0},\n",
    "        timeout=120,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    content = content.strip()\n",
    "    if content.startswith(\"```\"):\n",
    "        content = content.split(\"\\n\", 1)[1]\n",
    "    if content.endswith(\"```\"):\n",
    "        content = content.rsplit(\"```\", 1)[0]\n",
    "\n",
    "    return json.loads(content.strip())\n",
    "\n",
    "# --- Quick test du token ---\n",
    "try:\n",
    "    test_token = get_bearer_token()\n",
    "    print(f\"âœ… Bearer token obtenu ({len(test_token)} chars)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur token: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Pipeline ARGUS-style prÃªt (3 services)\")\n",
    "print(f\"   OCR A : Document Intelligence prebuilt-layout (API key)\")\n",
    "print(f\"   OCR B : Mistral Document AI mistral-document-ai-2505 (Bearer token / Entra ID)\")\n",
    "print(f\"   LLM   : GPT-5-chat (Bearer token / Entra ID)\")\n",
    "print(f\"   Schema: {len(ARGUS_SCHEMA)} champs de premier niveau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6998734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ 499 images totales, on traite les 20 premiÃ¨res\n",
      "\n",
      "\n",
      "============================================================\n",
      "  ğŸš€ Pipeline ARGUS avec OCR = DocIntel\n",
      "============================================================\n",
      "  [ 1/20] batch1-0001 â†’ cache âœ…\n",
      "  [ 2/20] batch1-0002 â†’ cache âœ…\n",
      "  [ 3/20] batch1-0003 â†’ cache âœ…\n",
      "  [ 4/20] batch1-0004 â†’ cache âœ…\n",
      "  [ 5/20] batch1-0005 â†’ cache âœ…\n",
      "  [ 6/20] batch1-0006 â†’ cache âœ…\n",
      "  [ 7/20] batch1-0007 â†’ cache âœ…\n",
      "  [ 8/20] batch1-0008 â†’ cache âœ…\n",
      "  [ 9/20] batch1-0009 â†’ cache âœ…\n",
      "  [10/20] batch1-0010 â†’ cache âœ…\n",
      "  [11/20] batch1-0011 â†’ cache âœ…\n",
      "  [12/20] batch1-0012 â†’ cache âœ…\n",
      "  [13/20] batch1-0013 â†’ cache âœ…\n",
      "  [14/20] batch1-0014 â†’ cache âœ…\n",
      "  [15/20] batch1-0015 â†’ cache âœ…\n",
      "  [16/20] batch1-0016 â†’ cache âœ…\n",
      "  [17/20] batch1-0017 â†’ DocIntel OCR...920 chars â†’ GPT-5 extraction...14 champs en 22.98s âœ…\n",
      "  [18/20] batch1-0018 â†’ cache âœ…\n",
      "  [19/20] batch1-0019 â†’ cache âœ…\n",
      "  [20/20] batch1-0020 â†’ cache âœ…\n",
      "\n",
      "  âœ… DocIntel: 20/20 rÃ©ussis\n",
      "\n",
      "============================================================\n",
      "  ğŸš€ Pipeline ARGUS avec OCR = Mistral\n",
      "============================================================\n",
      "  [ 1/20] batch1-0001 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 2/20] batch1-0002 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 3/20] batch1-0003 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 4/20] batch1-0004 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 5/20] batch1-0005 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 6/20] batch1-0006 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 7/20] batch1-0007 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 8/20] batch1-0008 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [ 9/20] batch1-0009 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [10/20] batch1-0010 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [11/20] batch1-0011 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [12/20] batch1-0012 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [13/20] batch1-0013 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [14/20] batch1-0014 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [15/20] batch1-0015 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [16/20] batch1-0016 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [17/20] batch1-0017 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [18/20] batch1-0018 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [19/20] batch1-0019 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "  [20/20] batch1-0020 â†’ Mistral OCR...âŒ 403 Client Error: Forbidden for url: https://content-understanding--resource.services.ai.azure.com/providers/mistral/azure/ocr\n",
      "\n",
      "  âœ… Mistral: 0/20 rÃ©ussis\n",
      "\n",
      "============================================================\n",
      "  âœ… Les deux pipelines ARGUS terminÃ©s !\n",
      "     DocIntel : 20/20\n",
      "     Mistral  : 0/20\n"
     ]
    }
   ],
   "source": [
    "# === Section 5: ExÃ©cuter ARGUS-style sur les 20 premiÃ¨res images ===\n",
    "# On limite Ã  20 documents (mÃªme set que Content Understanding)\n",
    "\n",
    "DOCS_FOLDER = r\"c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\batch1_1\"\n",
    "\n",
    "# Dossiers de sortie par variante OCR\n",
    "ARGUS_DI_OUTPUT = r\"c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\docu_results_batch1_1\\argus-style-di\"\n",
    "ARGUS_MISTRAL_OUTPUT = r\"c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\docu_results_batch1_1\\argus-style-mistral\"\n",
    "os.makedirs(ARGUS_DI_OUTPUT, exist_ok=True)\n",
    "os.makedirs(ARGUS_MISTRAL_OUTPUT, exist_ok=True)\n",
    "\n",
    "# âš ï¸ Limiter aux 20 premiÃ¨res images uniquement\n",
    "all_images = sorted(glob.glob(os.path.join(DOCS_FOLDER, \"batch1-*.jpg\")))\n",
    "images = all_images[:20]\n",
    "print(f\"ğŸ“ {len(all_images)} images totales, on traite les {len(images)} premiÃ¨res\\n\")\n",
    "\n",
    "def run_argus_pipeline(images, ocr_func, ocr_name, output_dir):\n",
    "    \"\"\"ExÃ©cute le pipeline ARGUS complet avec une fonction OCR donnÃ©e.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  ğŸš€ Pipeline ARGUS avec OCR = {ocr_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    for i, img_path in enumerate(images):\n",
    "        fname = os.path.basename(img_path).replace(\".jpg\", \"\")\n",
    "        out_file = os.path.join(output_dir, f\"{fname}.json\")\n",
    "        \n",
    "        # Skip si dÃ©jÃ  traitÃ© (et pas en erreur)\n",
    "        if os.path.exists(out_file):\n",
    "            with open(out_file, encoding=\"utf-8\") as fp:\n",
    "                cached = json.load(fp)\n",
    "            if not cached.get(\"error\"):\n",
    "                results.append(cached)\n",
    "                print(f\"  [{i+1:2d}/{len(images)}] {fname} â†’ cache âœ…\")\n",
    "                continue\n",
    "            else:\n",
    "                # Re-traiter les fichiers en erreur\n",
    "                os.remove(out_file)\n",
    "        \n",
    "        print(f\"  [{i+1:2d}/{len(images)}] {fname} â†’ \", end=\"\", flush=True)\n",
    "        t0 = time.time()\n",
    "        result = {\"file\": f\"{fname}.jpg\", \"ocr_method\": ocr_name, \"error\": None}\n",
    "        \n",
    "        try:\n",
    "            # Ã‰tape 1: OCR\n",
    "            print(f\"{ocr_name} OCR...\", end=\"\", flush=True)\n",
    "            ocr_text = ocr_func(img_path)\n",
    "            result[\"ocr_chars\"] = len(ocr_text)\n",
    "            result[\"ocr_text_preview\"] = ocr_text[:300]\n",
    "            print(f\"{len(ocr_text)} chars â†’ \", end=\"\", flush=True)\n",
    "            \n",
    "            # Ã‰tape 2: GPT-5-chat extraction\n",
    "            print(\"GPT-5 extraction...\", end=\"\", flush=True)\n",
    "            time.sleep(3)  # Rate limit\n",
    "            extracted = gpt_extract_argus_style(ocr_text, img_path)\n",
    "            result[\"extraction\"] = extracted\n",
    "            \n",
    "            fields_count = sum(1 for v in extracted.values() if v is not None and v != \"\" and v != [])\n",
    "            result[\"fields_with_value\"] = fields_count\n",
    "            result[\"total_fields\"] = len(extracted)\n",
    "            \n",
    "        except Exception as e:\n",
    "            result[\"error\"] = str(e)\n",
    "            result[\"fields_with_value\"] = 0\n",
    "            result[\"total_fields\"] = 0\n",
    "            print(f\"âŒ {e}\")\n",
    "        \n",
    "        result[\"time_seconds\"] = round(time.time() - t0, 2)\n",
    "        \n",
    "        with open(out_file, \"w\", encoding=\"utf-8\") as fp:\n",
    "            json.dump(result, fp, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        results.append(result)\n",
    "        if not result[\"error\"]:\n",
    "            print(f\"{result['fields_with_value']} champs en {result['time_seconds']}s âœ…\")\n",
    "    \n",
    "    ok = sum(1 for r in results if not r.get(\"error\"))\n",
    "    print(f\"\\n  âœ… {ocr_name}: {ok}/{len(results)} rÃ©ussis\")\n",
    "    return results\n",
    "\n",
    "# --- ExÃ©cution variante A : Document Intelligence ---\n",
    "argus_di_results = run_argus_pipeline(images, get_di_ocr_markdown, \"DocIntel\", ARGUS_DI_OUTPUT)\n",
    "\n",
    "# --- ExÃ©cution variante B : Mistral Doc AI ---\n",
    "argus_mistral_results = run_argus_pipeline(images, get_mistral_ocr_markdown, \"Mistral\", ARGUS_MISTRAL_OUTPUT)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  âœ… Les deux pipelines ARGUS terminÃ©s !\")\n",
    "print(f\"     DocIntel : {sum(1 for r in argus_di_results if not r.get('error'))}/{len(argus_di_results)}\")\n",
    "print(f\"     Mistral  : {sum(1 for r in argus_mistral_results if not r.get('error'))}/{len(argus_mistral_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19af596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "   COMPARAISON CÃ”TE Ã€ CÃ”TE : CONTENT UNDERSTANDING  vs  ARGUS+DocIntel  vs  ARGUS+Mistral\n",
      "========================================================================================================================\n",
      "\n",
      "Document           â”‚  CU Champs â”‚  CU Conf â”‚  DI Champs â”‚   DI OCR â”‚ DI t(s) â”‚  MI Champs â”‚   MI OCR â”‚ MI t(s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "batch1-0001        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚    1,203 â”‚    30.1 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0002        â”‚      17/31 â”‚     0.83 â”‚      14/15 â”‚      976 â”‚    27.8 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0003        â”‚      17/31 â”‚     0.83 â”‚      14/15 â”‚      812 â”‚    18.4 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0004        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚    1,004 â”‚    24.9 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0005        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      943 â”‚    26.6 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0006        â”‚       0/31 â”‚     0.72 â”‚      14/15 â”‚      810 â”‚    28.8 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0007        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚    1,204 â”‚    28.7 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0008        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚      911 â”‚    24.4 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0009        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚      586 â”‚    19.3 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0010        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚      649 â”‚    19.5 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0011        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      632 â”‚    22.6 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0012        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      780 â”‚    28.0 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0013        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      839 â”‚    26.1 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0014        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      526 â”‚    16.6 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0015        â”‚      17/31 â”‚     0.83 â”‚      14/15 â”‚    1,004 â”‚    27.3 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0016        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      945 â”‚    24.9 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0017        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚      920 â”‚    23.0 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0018        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚      953 â”‚    35.8 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0019        â”‚      17/31 â”‚     0.81 â”‚      14/15 â”‚      709 â”‚    21.2 â”‚          âŒ â”‚        - â”‚       -\n",
      "batch1-0020        â”‚      17/31 â”‚     0.82 â”‚      14/15 â”‚      983 â”‚    24.9 â”‚          âŒ â”‚        - â”‚       -\n",
      "\n",
      "========================================================================================================================\n",
      "   RÃ‰SUMÃ‰ AGRÃ‰GÃ‰\n",
      "========================================================================================================================\n",
      "  Content Understanding:\n",
      "    RÃ©ussis          : 19/20\n",
      "    Champs/doc (moy) : 17.0\n",
      "    Confidence (moy) : 0.819\n",
      "    Markdown (moy)   : 1,506\n",
      "\n",
      "  ARGUS + DocIntel OCR:\n",
      "    RÃ©ussis          : 20/20\n",
      "    Champs/doc (moy) : 14.0\n",
      "    Champs/doc (min) : 14\n",
      "    Champs/doc (max) : 14\n",
      "    OCR chars (moy)  : 869\n",
      "    Temps/doc (moy)  : 24.9s\n",
      "\n",
      "  ARGUS + Mistral OCR: aucun rÃ©sultat\n"
     ]
    }
   ],
   "source": [
    "# === Section 6: Comparaison cÃ´te Ã  cÃ´te â€” 3 mÃ©thodes ===\n",
    "print(f\"\\n{'='*120}\")\n",
    "print(f\"   COMPARAISON CÃ”TE Ã€ CÃ”TE : CONTENT UNDERSTANDING  vs  ARGUS+DocIntel  vs  ARGUS+Mistral\")\n",
    "print(f\"{'='*120}\")\n",
    "\n",
    "header = (f\"{'Document':<18} â”‚ {'CU Champs':>10} â”‚ {'CU Conf':>8} â”‚ \"\n",
    "          f\"{'DI Champs':>10} â”‚ {'DI OCR':>8} â”‚ {'DI t(s)':>7} â”‚ \"\n",
    "          f\"{'MI Champs':>10} â”‚ {'MI OCR':>8} â”‚ {'MI t(s)':>7}\")\n",
    "print(f\"\\n{header}\")\n",
    "print(f\"{'â”€'*18}â”€â”¼â”€{'â”€'*10}â”€â”¼â”€{'â”€'*8}â”€â”¼â”€{'â”€'*10}â”€â”¼â”€{'â”€'*8}â”€â”¼â”€{'â”€'*7}â”€â”¼â”€{'â”€'*10}â”€â”¼â”€{'â”€'*8}â”€â”¼â”€{'â”€'*7}\")\n",
    "\n",
    "for cu_m in cu_metrics:\n",
    "    fname = cu_m[\"file\"].replace(\".json\", \"\")\n",
    "    \n",
    "    di_m = next((r for r in argus_di_results if r[\"file\"].replace(\".jpg\", \"\") == fname), None)\n",
    "    mi_m = next((r for r in argus_mistral_results if r[\"file\"].replace(\".jpg\", \"\") == fname), None)\n",
    "    \n",
    "    cu_f = f\"{cu_m['fields_with_value']}/{cu_m['total_fields']}\"\n",
    "    cu_c = f\"{cu_m['avg_confidence']:.2f}\"\n",
    "    \n",
    "    if di_m and not di_m.get(\"error\"):\n",
    "        di_f = f\"{di_m['fields_with_value']}/{di_m['total_fields']}\"\n",
    "        di_o = f\"{di_m.get('ocr_chars', 0):,}\"\n",
    "        di_t = f\"{di_m.get('time_seconds', 0):.1f}\"\n",
    "    else:\n",
    "        di_f, di_o, di_t = (\"âŒ\", \"-\", \"-\") if di_m else (\"N/A\", \"N/A\", \"N/A\")\n",
    "    \n",
    "    if mi_m and not mi_m.get(\"error\"):\n",
    "        mi_f = f\"{mi_m['fields_with_value']}/{mi_m['total_fields']}\"\n",
    "        mi_o = f\"{mi_m.get('ocr_chars', 0):,}\"\n",
    "        mi_t = f\"{mi_m.get('time_seconds', 0):.1f}\"\n",
    "    else:\n",
    "        mi_f, mi_o, mi_t = (\"âŒ\", \"-\", \"-\") if mi_m else (\"N/A\", \"N/A\", \"N/A\")\n",
    "    \n",
    "    print(f\"{fname:<18} â”‚ {cu_f:>10} â”‚ {cu_c:>8} â”‚ {di_f:>10} â”‚ {di_o:>8} â”‚ {di_t:>7} â”‚ {mi_f:>10} â”‚ {mi_o:>8} â”‚ {mi_t:>7}\")\n",
    "\n",
    "# --- RÃ©sumÃ© agrÃ©gÃ© ---\n",
    "print(f\"\\n{'='*120}\")\n",
    "print(f\"   RÃ‰SUMÃ‰ AGRÃ‰GÃ‰\")\n",
    "print(f\"{'='*120}\")\n",
    "\n",
    "def summarize(results, name):\n",
    "    ok = [r for r in results if not r.get(\"error\")]\n",
    "    if not ok:\n",
    "        print(f\"  {name}: aucun rÃ©sultat\")\n",
    "        return\n",
    "    fields = [r[\"fields_with_value\"] for r in ok]\n",
    "    ocr_chars = [r.get(\"ocr_chars\", 0) for r in ok]\n",
    "    times = [r.get(\"time_seconds\", 0) for r in ok]\n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    RÃ©ussis          : {len(ok)}/{len(results)}\")\n",
    "    print(f\"    Champs/doc (moy) : {statistics.mean(fields):.1f}\")\n",
    "    print(f\"    Champs/doc (min) : {min(fields)}\")\n",
    "    print(f\"    Champs/doc (max) : {max(fields)}\")\n",
    "    print(f\"    OCR chars (moy)  : {statistics.mean(ocr_chars):,.0f}\")\n",
    "    print(f\"    Temps/doc (moy)  : {statistics.mean(times):.1f}s\")\n",
    "    print()\n",
    "\n",
    "cu_ok = [m for m in cu_metrics if m[\"fields_with_value\"] > 0]\n",
    "print(f\"  Content Understanding:\")\n",
    "print(f\"    RÃ©ussis          : {len(cu_ok)}/{len(cu_metrics)}\")\n",
    "print(f\"    Champs/doc (moy) : {statistics.mean([m['fields_with_value'] for m in cu_ok]):.1f}\")\n",
    "print(f\"    Confidence (moy) : {statistics.mean([m['avg_confidence'] for m in cu_ok if m['avg_confidence'] > 0]):.3f}\")\n",
    "print(f\"    Markdown (moy)   : {statistics.mean([m['markdown_chars'] for m in cu_metrics]):,.0f}\")\n",
    "print()\n",
    "\n",
    "summarize(argus_di_results, \"ARGUS + DocIntel OCR\")\n",
    "summarize(argus_mistral_results, \"ARGUS + Mistral OCR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
