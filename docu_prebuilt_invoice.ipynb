{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()  # charge les variables depuis .env\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb908db2",
   "metadata": {},
   "source": [
    "# ğŸ“„ Azure Content Understanding â€” Prebuilt Analyzer Test\n",
    "\n",
    "**Service** : Azure AI Content Understanding (REST API `2025-11-01`)  \n",
    "**Auth** : Azure AD (DefaultAzureCredential) â€” key auth disabled on this resource  \n",
    "**Plan** :  \n",
    "1. Acquire token once (cached)  \n",
    "2. Test available prebuilt analyzers on 1 doc  \n",
    "3. Run the best ones on 20 docs from `batch1_1`  \n",
    "4. Save JSON results to `docu_results_batch1_1/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests python-dotenv\n",
    "%pip install cryptography --only-binary=:all:\n",
    "%pip install azure-identity azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c887d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Token OK\n",
      "ğŸŒ Endpoint: https://aya-demo-ai.cognitiveservices.azure.com\n",
      "ğŸ“‚ 20 documents ready\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, glob, base64, requests\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
    "\n",
    "# â”€â”€ Config â”€â”€\n",
    "ENDPOINT       = \"https://aya-demo-ai.cognitiveservices.azure.com\"\n",
    "API_VERSION    = \"2025-11-01\"\n",
    "STORAGE_ACCOUNT = \"staicont179d75\"\n",
    "CONTAINER_NAME  = \"cu-temp\"\n",
    "DOCS_FOLDER    = r\"c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\batch1_1\"\n",
    "OUTPUT_FOLDER  = r\"c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\docu_results_batch1_1\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Azure AD Token (cached) â”€â”€\n",
    "credential = DefaultAzureCredential()\n",
    "_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "def auth():\n",
    "    global _token\n",
    "    if time.time() > _token.expires_on - 120:\n",
    "        _token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "    return {\"Authorization\": f\"Bearer {_token.token}\"}\n",
    "\n",
    "# â”€â”€ Blob Storage client (for URL-based Content Understanding) â”€â”€\n",
    "blob_service = BlobServiceClient(\n",
    "    f\"https://{STORAGE_ACCOUNT}.blob.core.windows.net\",\n",
    "    credential=credential\n",
    ")\n",
    "# Get user delegation key for SAS generation (valid 2h)\n",
    "_udk_start = datetime.now(timezone.utc)\n",
    "_udk_expiry = _udk_start + timedelta(hours=2)\n",
    "_user_delegation_key = blob_service.get_user_delegation_key(_udk_start, _udk_expiry)\n",
    "\n",
    "def upload_to_blob(file_path):\n",
    "    \"\"\"Upload file to Azure Blob Storage and return a SAS URL (valid 2h).\"\"\"\n",
    "    blob_name = os.path.basename(file_path)\n",
    "    blob_client = blob_service.get_blob_client(CONTAINER_NAME, blob_name)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        blob_client.upload_blob(f, overwrite=True)\n",
    "    sas = generate_blob_sas(\n",
    "        account_name=STORAGE_ACCOUNT,\n",
    "        container_name=CONTAINER_NAME,\n",
    "        blob_name=blob_name,\n",
    "        user_delegation_key=_user_delegation_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=_udk_expiry,\n",
    "    )\n",
    "    return f\"https://{STORAGE_ACCOUNT}.blob.core.windows.net/{CONTAINER_NAME}/{blob_name}?{sas}\"\n",
    "\n",
    "# â”€â”€ First 20 images â”€â”€\n",
    "all_images = sorted(glob.glob(os.path.join(DOCS_FOLDER, \"*.jpg\")))[:20]\n",
    "print(f\"ğŸ”‘ Token OK\")\n",
    "print(f\"ğŸŒ Endpoint: {ENDPOINT}\")\n",
    "print(f\"ğŸ“¦ Blob Storage: {STORAGE_ACCOUNT}/{CONTAINER_NAME}\")\n",
    "print(f\"ğŸ“‚ {len(all_images)} documents ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b1fa5",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 1 â€” Test which prebuilt analyzers work on this resource\n",
    "\n",
    "Quick test on 1 document to identify working analyzers before running the full batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing prebuilt-invoice on batch1-0001.jpg...\n",
      "   (first call may take 3-6 min while models deploy)\n",
      "\n",
      "   âœ“ Submitted (202). Polling (10 min timeout)...\n",
      "\n",
      "   âœ… prebuilt-invoice SUCCESS! (8s)\n",
      "      Fields: 31 | Markdown: 13 chars\n",
      "      Field names: ['AmountDue', 'BalanceForward', 'BillingAddress', 'BillingAddressRecipient', 'CountryRegion', 'CustomerAddress', 'CustomerAddressRecipient', 'CustomerId', 'CustomerName', 'CustomerTaxId']\n",
      "\n",
      "ğŸ“Œ Analyzers for batch: ['prebuilt-invoice']\n"
     ]
    }
   ],
   "source": [
    "def submit(image_path, analyzer_id):\n",
    "    \"\"\"Upload image to Blob Storage, then POST URL to Content Understanding.\"\"\"\n",
    "    blob_url = upload_to_blob(image_path)\n",
    "    url = f\"{ENDPOINT}/contentunderstanding/analyzers/{analyzer_id}:analyze?api-version={API_VERSION}\"\n",
    "    r = requests.post(url, headers={**auth(), \"Content-Type\": \"application/json\"},\n",
    "                      json={\"inputs\": [{\"url\": blob_url}]})\n",
    "    if r.status_code != 202:\n",
    "        raise RuntimeError(f\"{r.status_code}: {r.text[:500]}\")\n",
    "    return r.headers[\"Operation-Location\"]\n",
    "\n",
    "def poll(op_url, timeout=600):\n",
    "    \"\"\"Poll operation URL until Succeeded (default 10 min timeout).\"\"\"\n",
    "    for i in range(timeout // 5):\n",
    "        time.sleep(5)\n",
    "        r = requests.get(op_url, headers=auth())\n",
    "        r.raise_for_status()\n",
    "        res = r.json()\n",
    "        st = res.get(\"status\", \"\")\n",
    "        if st == \"Succeeded\": return res\n",
    "        if st in (\"Failed\",\"Canceled\"):\n",
    "            raise RuntimeError(json.dumps(res.get(\"error\", res), indent=2))\n",
    "        if i % 6 == 5:\n",
    "            print(f\"    ...still waiting ({(i+1)*5}s, status={st})\", flush=True)\n",
    "    raise TimeoutError(\"Timeout\")\n",
    "\n",
    "# â”€â”€ Test just prebuilt-invoice first (may take time on first call) â”€â”€\n",
    "test_img = all_images[0]\n",
    "print(f\"ğŸ§ª Testing prebuilt-invoice on {os.path.basename(test_img)}...\")\n",
    "print(f\"   (uploading to blob, then submitting via URL)\\n\")\n",
    "\n",
    "t0 = time.time()\n",
    "try:\n",
    "    op = submit(test_img, \"prebuilt-invoice\")\n",
    "    print(f\"   âœ“ Submitted (202). Polling (10 min timeout)...\")\n",
    "    res = poll(op, timeout=600)\n",
    "    dt = time.time() - t0\n",
    "    c = res.get(\"result\",{}).get(\"contents\",[])\n",
    "    block = c[0] if c else {}\n",
    "    fields = block.get(\"fields\",{})\n",
    "    md = block.get(\"markdown\",\"\")\n",
    "    # Count fields with actual values\n",
    "    has_val = sum(1 for f in fields.values() if isinstance(f, dict) and\n",
    "                  any(k.startswith(\"value\") and k not in (\"valueObject\",) for k in f.keys()))\n",
    "    print(f\"\\n   âœ… prebuilt-invoice SUCCESS! ({dt:.0f}s)\")\n",
    "    print(f\"      Fields: {has_val}/{len(fields)} with values | Markdown: {len(md)} chars\")\n",
    "    print(f\"      Markdown preview: {md[:200]}\")\n",
    "    ANALYZERS = [\"prebuilt-invoice\"]\n",
    "except Exception as e:\n",
    "    dt = time.time() - t0\n",
    "    print(f\"\\n   âŒ prebuilt-invoice failed ({dt:.0f}s): {e}\")\n",
    "    ANALYZERS = [\"prebuilt-layout\", \"prebuilt-read\"]\n",
    "    print(f\"   Falling back to: {ANALYZERS}\")\n",
    "\n",
    "print(f\"\\nğŸ“Œ Analyzers for batch: {ANALYZERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ba069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking if previous prebuilt-invoice job completed...\n",
      "\n",
      "   Submitted. Polling with 10 min timeout...\n",
      "\n",
      "âœ… prebuilt-invoice works! (7s)\n",
      "   Fields: 31 | Markdown: 13 chars\n",
      "   Field names: ['AmountDue', 'BalanceForward', 'BillingAddress', 'BillingAddressRecipient', 'CountryRegion', 'CustomerAddress', 'CustomerAddressRecipient', 'CustomerId', 'CustomerName', 'CustomerTaxId', 'DueDate', 'InvoiceDate', 'InvoiceId', 'LineItems', 'PaymentTerm', 'PONumber', 'RemittanceAddress', 'RemittanceAddressRecipient', 'ServiceAddress', 'ServiceAddressRecipient', 'ShippingAddress', 'ShippingAddressRecipient', 'SubtotalAmount', 'TaxDetails', 'TotalAmount', 'TotalDiscountAmount', 'TotalTaxAmount', 'VendorAddress', 'VendorAddressRecipient', 'VendorName', 'VendorTaxId']\n",
      "\n",
      "ğŸ“Œ Will use: ['prebuilt-invoice'] for the batch!\n"
     ]
    }
   ],
   "source": [
    "# Re-test prebuilt-invoice if needed (skip if already succeeded above)\n",
    "if ANALYZERS != [\"prebuilt-invoice\"]:\n",
    "    print(\"ğŸ” Re-testing prebuilt-invoice...\\n\")\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        op = submit(all_images[0], \"prebuilt-invoice\")\n",
    "        print(f\"   Submitted. Polling with 10 min timeout...\")\n",
    "        res = poll(op, timeout=600)\n",
    "        dt = time.time() - t0\n",
    "        c = res.get(\"result\",{}).get(\"contents\",[])\n",
    "        block = c[0] if c else {}\n",
    "        fields = block.get(\"fields\",{})\n",
    "        md = block.get(\"markdown\",\"\")\n",
    "        has_val = sum(1 for f in fields.values() if isinstance(f, dict) and\n",
    "                      any(k.startswith(\"value\") and k not in (\"valueObject\",) for k in f.keys()))\n",
    "        print(f\"\\nâœ… prebuilt-invoice works! ({dt:.0f}s)\")\n",
    "        print(f\"   Fields: {has_val}/{len(fields)} with values | Markdown: {len(md)} chars\")\n",
    "        ANALYZERS = [\"prebuilt-invoice\"]\n",
    "    except Exception as e:\n",
    "        dt = time.time() - t0\n",
    "        print(f\"\\nâŒ Still failing ({dt:.0f}s): {e}\")\n",
    "        ANALYZERS = [\"prebuilt-layout\", \"prebuilt-read\"]\n",
    "    print(f\"\\nğŸ“Œ Analyzers: {ANALYZERS}\")\n",
    "else:\n",
    "    print(\"âœ… prebuilt-invoice already confirmed working. Skipping re-test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43d969",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 2 â€” Batch analysis: submit ALL, then poll ALL\n",
    "\n",
    "Submits all requests first (fast), then collects results â€” much faster than sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6bfe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Submitting all requests...\n",
      "  âœ“ [1/20] batch1-0001.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [2/20] batch1-0002.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [3/20] batch1-0003.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [4/20] batch1-0004.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [5/20] batch1-0005.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [6/20] batch1-0006.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [7/20] batch1-0007.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [8/20] batch1-0008.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [9/20] batch1-0009.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [10/20] batch1-0010.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [11/20] batch1-0011.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [12/20] batch1-0012.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [13/20] batch1-0013.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [14/20] batch1-0014.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [15/20] batch1-0015.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [16/20] batch1-0016.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [17/20] batch1-0017.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [18/20] batch1-0018.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [19/20] batch1-0019.jpg â†’ prebuilt-invoice\n",
      "  âœ“ [20/20] batch1-0020.jpg â†’ prebuilt-invoice\n",
      "\n",
      "ğŸ“¤ 20 jobs submitted. Waiting 8s before polling...\n",
      "\n",
      "ğŸ“¥ Collecting results...\n",
      "  âœ… [1/20] batch1-0001.jpg|prebuilt-invoice 42s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (invoice) Ã©mise par la sociÃ©tÃ© Andrews, Kirby and Valdez Ã  Becker Ltd, datÃ©e du 13/04/2013. Le montant total TTC\n",
      "  âœ… [2/20] batch1-0002.jpg|prebuilt-invoice 51s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Il s'agit d'une facture (Invoice no: 12847181) Ã©mise par Fitzpatrick and Sons (Spencerport, NY, USA) Ã  destination de Duncan PLC (DPO AP 819\n",
      "  âœ… [3/20] batch1-0003.jpg|prebuilt-invoice 59s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ [LLM error: 429 Client Error: Too Many Requests for url: https://aya-demo-ai.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/com\n",
      "  âœ… [4/20] batch1-0004.jpg|prebuilt-invoice 65s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ [LLM error: 429 Client Error: Too Many Requests for url: https://aya-demo-ai.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/com\n",
      "  âœ… [5/20] batch1-0005.jpg|prebuilt-invoice 71s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ [LLM error: 429 Client Error: Too Many Requests for url: https://aya-demo-ai.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/com\n",
      "  âœ… [6/20] batch1-0006.jpg|prebuilt-invoice 77s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ [LLM error: 429 Client Error: Too Many Requests for url: https://aya-demo-ai.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/com\n",
      "    ...still waiting (30s, status=Running)\n",
      "  âœ… [7/20] batch1-0007.jpg|prebuilt-invoice 125s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ [LLM error: 429 Client Error: Too Many Requests for url: https://aya-demo-ai.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/com\n",
      "  âœ… [8/20] batch1-0008.jpg|prebuilt-invoice 131s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ [LLM error: 429 Client Error: Too Many Requests for url: https://aya-demo-ai.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/com\n",
      "    ...still waiting (30s, status=Running)\n",
      "  âœ… [9/20] batch1-0009.jpg|prebuilt-invoice 186s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture Ã©mise par Padilla-Miller (53017 Lopez Locks, Alecborough, OH) Ã  l'attention de Johnson Ltd (West Jason, CT). La \n",
      "  âœ… [10/20] batch1-0010.jpg|prebuilt-invoice 194s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (invoice) Ã©mise par \"Michael, Farrell and Lee\" Ã  \"Collins, Barrett and Schroeder\" en date du 25/06/2014. Le mont\n",
      "  âœ… [11/20] batch1-0011.jpg|prebuilt-invoice 202s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (invoice) Ã©mise par la sociÃ©tÃ© Torres and Sons Ã  l'attention de Dennis, Levy and Bowen, datÃ©e du 20/03/2016. Le \n",
      "  âœ… [12/20] batch1-0012.jpg|prebuilt-invoice 211s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (invoice) Ã©mise par Nicholson, Miller and Webster (USS Lee) Ã  McCormick and Sons, datÃ©e du 22/11/2013. Le montan\n",
      "  âœ… [13/20] batch1-0013.jpg|prebuilt-invoice 219s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (invoice) Ã©mise par la sociÃ©tÃ© Schmidt LLC Ã  l'attention de la sociÃ©tÃ© Allen PLC, datÃ©e du 17/10/2015. Le montan\n",
      "  âœ… [14/20] batch1-0014.jpg|prebuilt-invoice 228s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture Ã©mise par Tran, Hurst and Rodgers Ã  Stephenson Inc, datÃ©e du 31/01/2021. Le montant total TTC est de 24,95 $ pou\n",
      "  âœ… [15/20] batch1-0015.jpg|prebuilt-invoice 236s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Il s'agit d'une facture (invoice no: 46506594) Ã©mise le 03/12/2012 par Porter-Perkins (East Alyssamouth, KS) Ã  Castaneda LLC (East Chelseyto\n",
      "  âœ… [16/20] batch1-0016.jpg|prebuilt-invoice 245s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Il s'agit d'une facture (Invoice no: 44456646) Ã©mise par Austin and Sons (Johnsonburgh, IA, USA) Ã  Delacruz, Hinton and Mckinney (North Cody\n",
      "  âœ… [17/20] batch1-0017.jpg|prebuilt-invoice 254s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (Invoice no: 98858130) Ã©mise le 28/01/2021 par la sociÃ©tÃ© Dominguez, Jackson and Steele Ã  Michaelbury, RI, Ã  des\n",
      "  âœ… [18/20] batch1-0018.jpg|prebuilt-invoice 262s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture Ã©mise par la sociÃ©tÃ© Lopez, Murray and Johnston (Emilyshire, IN) Ã  destination de White Ltd (Port Stacey, NM), d\n",
      "  âœ… [19/20] batch1-0019.jpg|prebuilt-invoice 271s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Il s'agit d'une facture (invoice) Ã©mise par la sociÃ©tÃ© \"Lozano, Wang and Smith\" Ã  \"Evans, Curtis and Salinas\" en date du 01/11/2015. Le mont\n",
      "  âœ… [20/20] batch1-0020.jpg|prebuilt-invoice 280s\n",
      "     âš ï¸ Fields with values: 0/31\n",
      "     ğŸ“ Ce document est une facture (invoice) Ã©mise par Kerr, Ryan and Gomez Ã  Mason Ltd, datÃ©e du 18/02/2014. Le montant total TTC est de 327,08â€¯$,\n",
      "\n",
      "ğŸ‰ Done! Results in c:\\Users\\ayac\\Downloads\\archive (1)\\batch_1\\batch_1\\docu_results_batch1_1\n"
     ]
    }
   ],
   "source": [
    "all_metrics = {a: [] for a in ANALYZERS}\n",
    "jobs = []  # (img_path, analyzer, op_url, t0)\n",
    "\n",
    "# â”€â”€ Helper: extract field values (name â†’ value) recursively â”€â”€\n",
    "def extract_field_values(fields_dict):\n",
    "    \"\"\"Flatten fields into {name: value} dict.\n",
    "    Only keeps fields that have actual values (valueString, valueNumber, etc.),\n",
    "    skips fields that only have schema definitions (type, no value).\"\"\"\n",
    "    result = {}\n",
    "    for name, obj in fields_dict.items():\n",
    "        if not isinstance(obj, dict):\n",
    "            continue\n",
    "        # Skip fields that only have schema (type) but no actual value\n",
    "        if set(obj.keys()) <= {\"type\", \"valueObject\"} and \"valueObject\" in obj:\n",
    "            # Check if sub-fields have actual values\n",
    "            sub = extract_field_values(obj[\"valueObject\"])\n",
    "            if sub:  # only add if sub-fields have real values\n",
    "                result[name] = sub\n",
    "        elif set(obj.keys()) <= {\"type\"}:\n",
    "            continue  # schema-only field, skip\n",
    "        else:\n",
    "            # Field has actual value\n",
    "            val = obj.get(\"valueString\") or obj.get(\"valueNumber\") or obj.get(\"valueDate\") or obj.get(\"content\") or obj.get(\"value\")\n",
    "            if val is not None:\n",
    "                result[name] = val\n",
    "            elif \"valueObject\" in obj:\n",
    "                sub = extract_field_values(obj[\"valueObject\"])\n",
    "                if sub:\n",
    "                    result[name] = sub\n",
    "            elif \"valueArray\" in obj:\n",
    "                arr = []\n",
    "                for item in obj[\"valueArray\"]:\n",
    "                    if isinstance(item, dict) and \"valueObject\" in item:\n",
    "                        sub = extract_field_values(item[\"valueObject\"])\n",
    "                        if sub:\n",
    "                            arr.append(sub)\n",
    "                    elif isinstance(item, dict):\n",
    "                        v = item.get(\"valueString\") or item.get(\"content\") or item.get(\"value\")\n",
    "                        if v:\n",
    "                            arr.append(v)\n",
    "                if arr:\n",
    "                    result[name] = arr\n",
    "    return result\n",
    "\n",
    "# â”€â”€ Helper: LLM description via GPT-4.1 Vision (multimodal) â”€â”€\n",
    "GPT_DEPLOYMENT = \"gpt-4.1\"\n",
    "\n",
    "def llm_describe(image_path, fname):\n",
    "    \"\"\"Send the actual image to GPT-4.1 Vision for a global document description.\"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    url = f\"{ENDPOINT}/openai/deployments/{GPT_DEPLOYMENT}/chat/completions?api-version=2024-12-01-preview\"\n",
    "    body = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Tu es un assistant d'analyse documentaire expert. Tu analyses des documents scannÃ©s (factures, devis, bons de commande, etc.) et tu fournis une description globale concise.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"Analyse cette image du document \\\"{fname}\\\". Donne une description globale en 2-3 phrases en franÃ§ais: quel type de document est-ce, qui est l'Ã©metteur, le destinataire, le montant total, la date, et tout Ã©lÃ©ment clÃ©.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_b64}\", \"detail\": \"high\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0.3,\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(url, headers={**auth(), \"Content-Type\": \"application/json\"}, json=body)\n",
    "        r.raise_for_status()\n",
    "        return r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        return f\"[LLM error: {e}]\"\n",
    "\n",
    "# â”€â”€ Phase 1: Submit all â”€â”€\n",
    "print(\"ğŸ“¤ Submitting all requests...\")\n",
    "for i, img in enumerate(all_images, 1):\n",
    "    fname = os.path.basename(img)\n",
    "    for aid in ANALYZERS:\n",
    "        try:\n",
    "            op = submit(img, aid)\n",
    "            jobs.append((img, aid, op, time.time()))\n",
    "            print(f\"  âœ“ [{i}/20] {fname} â†’ {aid}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— [{i}/20] {fname} â†’ {aid}: {e}\")\n",
    "            all_metrics[aid].append({\"document\": fname, \"analyzer\": aid,\n",
    "                                     \"error\": str(e), \"time_seconds\": 0})\n",
    "\n",
    "print(f\"\\nğŸ“¤ {len(jobs)} jobs submitted. Waiting 8s before polling...\")\n",
    "time.sleep(8)\n",
    "\n",
    "# â”€â”€ Phase 2: Collect results â”€â”€\n",
    "print(\"\\nğŸ“¥ Collecting results...\")\n",
    "done = 0\n",
    "for img, aid, op_url, t0 in jobs:\n",
    "    fname = os.path.basename(img)\n",
    "    dname = os.path.splitext(fname)[0]\n",
    "    done += 1\n",
    "    try:\n",
    "        res = poll(op_url)\n",
    "        dt = time.time() - t0\n",
    "        c = res.get(\"result\",{}).get(\"contents\",[])\n",
    "        block = c[0] if c else {}\n",
    "        fields = block.get(\"fields\", {})\n",
    "        md = block.get(\"markdown\", \"\")\n",
    "\n",
    "        # Extract field values (only real values, skip schema-only)\n",
    "        field_values = extract_field_values(fields)\n",
    "\n",
    "        # Count field confidences recursively\n",
    "        confs = []\n",
    "        def _gc(o):\n",
    "            if isinstance(o, dict):\n",
    "                if \"confidence\" in o: confs.append(o[\"confidence\"])\n",
    "                for v in o.values(): _gc(v)\n",
    "            elif isinstance(o, list):\n",
    "                for x in o: _gc(x)\n",
    "        _gc(fields)\n",
    "\n",
    "        # Generate global LLM description via GPT-4.1 Vision (image directe)\n",
    "        description = llm_describe(img, fname)\n",
    "\n",
    "        m = {\"document\": fname, \"analyzer\": aid, \"time_seconds\": round(dt,1),\n",
    "             \"num_fields\": len(fields), \"num_fields_with_values\": len(field_values),\n",
    "             \"markdown_len\": len(md),\n",
    "             \"avg_confidence\": round(sum(confs)/len(confs),4) if confs else None,\n",
    "             \"num_tables\": len(block.get(\"tables\",[])),\n",
    "             \"num_pages\": len(block.get(\"pages\",[])),\n",
    "             \"field_values\": field_values,\n",
    "             \"description\": description}\n",
    "        all_metrics[aid].append(m)\n",
    "\n",
    "        # Save JSON (with field values + description)\n",
    "        enriched_result = res.copy()\n",
    "        enriched_result[\"_extracted\"] = {\n",
    "            \"field_values\": field_values,\n",
    "            \"description\": description\n",
    "        }\n",
    "        folder = os.path.join(OUTPUT_FOLDER, aid)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        with open(os.path.join(folder, f\"{dname}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(enriched_result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        # Print summary\n",
    "        status_icon = \"ğŸ“‹\" if field_values else \"âš ï¸\"\n",
    "        print(f\"  âœ… [{done}/{len(jobs)}] {fname}|{aid} {dt:.0f}s\")\n",
    "        print(f\"     {status_icon} Fields with values: {len(field_values)}/{len(fields)}\")\n",
    "        if field_values:\n",
    "            top = {k: (str(v)[:50] if not isinstance(v, (list,dict)) else f\"[{type(v).__name__}]\")\n",
    "                   for k, v in list(field_values.items())[:5]}\n",
    "            print(f\"     ğŸ“‹ {top}\")\n",
    "        print(f\"     ğŸ“ {description[:140]}\")\n",
    "    except Exception as e:\n",
    "        dt = time.time() - t0\n",
    "        print(f\"  âŒ [{done}/{len(jobs)}] {fname}|{aid} {dt:.0f}s {str(e)[:80]}\")\n",
    "        all_metrics[aid].append({\"document\": fname, \"analyzer\": aid,\n",
    "                                 \"error\": str(e), \"time_seconds\": round(dt,1)})\n",
    "\n",
    "print(f\"\\nğŸ‰ Done! Results in {OUTPUT_FOLDER}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
